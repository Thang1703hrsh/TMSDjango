{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Child.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\TMSDjango\\temporary\\evalua.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/TMSDjango/temporary/evalua.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dfChild \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mChild.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/TMSDjango/temporary/evalua.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dfParent \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mParent.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/TMSDjango/temporary/evalua.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dfOrder \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mOrder.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Child.csv'"
     ]
    }
   ],
   "source": [
    "dfChild = pd.read_csv(\"Child.csv\")\n",
    "dfParent = pd.read_csv(\"Parent.csv\")\n",
    "dfOrder = pd.read_csv(\"Order.csv\")\n",
    "\n",
    "dfReqStockoutProductDetail = pd.read_csv(\"ReqStockoutProductDetail.csv\") # Request Stockout Product Detail\n",
    "dfOutSourcingDetail = pd.read_csv(\"OutSourcingDetail.csv\") # Outsourcing Detail\n",
    "dfReturnProduct = pd.read_csv(\"ReturnProduct.csv\") # Return Product\n",
    "dfPurchaseOrder = pd.read_csv(\"PurchaseOrder.csv\") # Purchase Order\n",
    "dfStockInPurchaseOrder = pd.read_csv(\"StockInPurchaseOrder.csv\") # Purchase Order\n",
    "dfOutSourcingQuota = pd.read_csv(\"OutSourcingQuota.csv\")\n",
    "# dfOutSourcing = pd.read_csv(\"OutSourcing.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutSourcingQuota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutSourcingQuota.merge(dfChild , left_on = 'product_id' , right_on= 'parent_product' , how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChild[dfChild['child_product'] == 84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPurchaseOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStockInPurchaseOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPurchaseOrder = dfPurchaseOrder.merge(dfStockInPurchaseOrder,on = 'product_id' , how = 'outer')\n",
    "dfPurchaseOrder = dfPurchaseOrder.replace(np.nan, 0)\n",
    "dfPurchaseOrder[\"material_not_in_stock\"] = dfPurchaseOrder[\"purchase_order_quantity\"] - dfPurchaseOrder['quantity_in_stock_purchase_order']\n",
    "dfPurchaseOrder[dfPurchaseOrder['material_not_in_stock'] < 0] = 0\n",
    "dfPurchaseOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReturnProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfParent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfParent.loc[dfParent['parent_product'] == 8422]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOrder_drop_dup = dfOrder.drop_duplicates(subset=['order_code', 'product_code'], keep='first').reset_index(drop= True)\n",
    "dfOrder_groupby_sum = dfOrder.groupby(['order_code', 'product_code'], as_index=False)['stockout_quantity'].sum()\n",
    "dfOrder_groupby_sum.sort_values(by = ['stockout_quantity'])\n",
    "dfOrder = pd.merge(dfOrder_drop_dup , dfOrder_groupby_sum, on=['order_code', 'product_code'], how='inner').drop(columns = ['stockout_quantity_x']).rename(columns = {\"stockout_quantity_y\":\"stockout_quantity\"})\n",
    "dfOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProductionOrder = dfOrder[['parent_product' , 'production_order_quantity', 'stockout_quantity']]\n",
    "dfProductionOrder.sort_values(by = ['parent_product'])\n",
    "dfProductionOrderDetail = dfProductionOrder.groupby(['parent_product'], as_index=False)['production_order_quantity' , 'stockout_quantity'].sum()\n",
    "dfProductionOrderDetail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutSourcingDetail.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfReqStockoutProductDetail.merge(dfOutSourcingDetail, on = 'product_id' , how = 'outer')\n",
    "df = df.merge(dfReturnProduct, on = 'product_id' , how = 'outer')\n",
    "df.rename(columns = {'product_id':'parent_product'}, inplace = True)\n",
    "df = dfProductionOrderDetail.merge(df, on = 'parent_product' , how = 'outer')\n",
    "df = dfParent.merge(df, on = 'parent_product' , how = 'outer').drop(columns = ['is_outsourcing'])\n",
    "df = df.fillna(0).reset_index(drop= True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['parent_product'] == 3802]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_production_need'] =  df['production_order_quantity'] + df['quantity_req_stockout'] + df['outsourcing_quantity'] + df['return_request_quantity']\n",
    "df['total_exported'] = df['stockout_quantity'] + df['exported_req_quantity'] + df['quantity_stock_in'] + df['returned_quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temporary_production_inventory'] =  df['product_quantity'] - (df['total_production_need'] - df['total_exported'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProductionNeedsAndExported = df\n",
    "dfProductionNeedsAndExported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfParent[dfParent['parent_product'] == 86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfParent.loc[dfParent['parent_product'] == 8422]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOrder.loc[dfOrder['order_code'] == \"NXK-BLACK-01295-VM-Gray-L-POJK3G\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOrder_drop_dup = dfOrder.drop_duplicates(subset=['order_code', 'product_code'], keep='first').reset_index(drop= True)\n",
    "dfOrder_groupby_sum = dfOrder.groupby(['order_code', 'product_code'], as_index=False)['stockout_quantity'].sum()\n",
    "dfOrder_groupby_sum.sort_values(by = ['stockout_quantity'])\n",
    "dfOrder = pd.merge(dfOrder_drop_dup , dfOrder_groupby_sum, on=['order_code', 'product_code'], how='inner').drop(columns = ['stockout_quantity_x']).rename(columns = {\"stockout_quantity_y\":\"stockout_quantity\"})\n",
    "dfOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChild2 = dfChild.drop_duplicates(keep='first').reset_index(drop = True)\n",
    "dfChild2 = dfChild2.sort_values(by=['parent_product']).reset_index(drop = True)\n",
    "dfChild3 = pd.merge(dfChild2 , dfParent[['parent_product','product_quantity','temporary_quantity']], left_on='child_product', right_on='parent_product', how='inner').drop(columns = ['parent_product_y']).rename(columns = {\"parent_product_x\":\"parent_product\"})\n",
    "dfChild3 = dfChild3.reset_index(drop = True)\n",
    "g = dfChild3.groupby([\"parent_product\"]).cumcount().add(1)\n",
    "dfChildMerge = dfChild3.set_index([\"parent_product\", g]).unstack(fill_value=0).sort_index(axis=1, level=1)\n",
    "dfChildMerge.columns = [\"{}{}\".format(a, b) for a, b in dfChildMerge.columns]\n",
    "\n",
    "dfChildMerge = dfChildMerge.reset_index()\n",
    "\n",
    "dfChildMerge = dfChildMerge.replace(np.nan, 0)\n",
    "dfChildMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChildMerge[dfChildMerge['parent_product'] == 8522]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChildMerge[dfChildMerge['quota5'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeMaterialOrder(dfChild, dfParent, dfOrder):\n",
    "   dfChild2 = dfChild.drop_duplicates(keep='first').reset_index(drop = True)\n",
    "   dfChild2 = dfChild2.sort_values(by=['parent_product']).reset_index(drop = True)\n",
    "   dfChild3 = pd.merge(dfChild2 , dfParent[['parent_product','product_quantity','temporary_quantity']], left_on='child_product', right_on='parent_product', how='inner').drop(columns = ['parent_product_y']).rename(columns = {\"parent_product_x\":\"parent_product\"})\n",
    "   dfChild3 = dfChild3.reset_index(drop = True)\n",
    "   g = dfChild3.groupby([\"parent_product\"]).cumcount().add(1)\n",
    "   dfChildMerge = dfChild3.set_index([\"parent_product\", g]).unstack(fill_value=0).sort_index(axis=1, level=1)\n",
    "   dfChildMerge.columns = [\"{}{}\".format(a, b) for a, b in dfChildMerge.columns]\n",
    "\n",
    "   dfChildMerge = dfChildMerge.reset_index()\n",
    "\n",
    "   dfChildMerge = dfChildMerge.replace(np.nan, 0)\n",
    "   dfTotalMate = pd.merge(dfParent, dfChildMerge, on='parent_product', how='left')\n",
    "   dfTotalMate = dfTotalMate.replace(np.nan, 0)\n",
    "   \n",
    "   dfTotalMate = dfTotalMate.drop(dfTotalMate[(dfTotalMate['child_product1'] == 0) & (dfTotalMate['is_outsourcing'] == 1)].index).reset_index(drop = True)\n",
    "   new_col1 = ['parent_product','product_code' , 'product_quantity' ,'temporary_quantity', 'is_outsourcing', \n",
    "      'product_code1', 'child_product1', 'quota1',\n",
    "      'product_quantity1', 'temporary_quantity1', 'product_code2',\n",
    "      'child_product2', 'quota2', 'product_quantity2',\n",
    "      'temporary_quantity2', 'product_code3', 'child_product3', 'quota3',\n",
    "      'product_quantity3', 'temporary_quantity3', 'product_code4',\n",
    "      'child_product4', 'quota4', 'product_quantity4',\n",
    "      'temporary_quantity4', 'product_code5', 'child_product5', 'quota5',\n",
    "      'product_quantity5', 'temporary_quantity5']\n",
    "   \n",
    "   dfTotalMate= dfTotalMate.reindex(columns=new_col1)\n",
    "   dfTotalMate = dfTotalMate.sort_values(by= ['parent_product']).reset_index(drop = True) \n",
    "\n",
    "   dfTotal = pd.merge(dfOrder , dfTotalMate, left_on='product_code', right_on='product_code', how='left')\n",
    "   dfTotal = dfTotal.reset_index(drop = True)\n",
    "   new_col2 = ['order_code' , 'position' , 'total_quota', 'stockout_quantity',\n",
    "      'parent_product' , 'product_code' , 'product_quantity',\n",
    "      'temporary_quantity', 'is_outsourcing' , 'product_code1', 'child_product1', 'quota1',\n",
    "      'product_quantity1', 'temporary_quantity1', 'product_code2',\n",
    "      'child_product2', 'quota2', 'product_quantity2',\n",
    "      'temporary_quantity2', 'product_code3', 'child_product3', 'quota3',\n",
    "      'product_quantity3', 'temporary_quantity3', 'product_code4',\n",
    "      'child_product4', 'quota4', 'product_quantity4',\n",
    "      'temporary_quantity4', 'product_code5', 'child_product5', 'quota5',\n",
    "      'product_quantity5', 'temporary_quantity5']\n",
    "   \n",
    "   dfTotal=dfTotal.reindex(columns=new_col2)\n",
    "\n",
    "   dfTotal = dfTotal[:1000] \n",
    "   dfTotalReverse = dfTotal[::-1]\n",
    "   dfTotalReverse = dfTotalReverse.reset_index(drop = True)\n",
    "   dfTotalReverse = dfTotalReverse.drop(dfTotalReverse[np.isnan(dfTotalReverse['parent_product']) == True].index).reset_index(drop = True)\n",
    "   return dfTotalMate, dfTotalReverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTotalMate, dfTotalReverse = mergeMaterialOrder(dfChild , dfParent, dfOrder)\n",
    "dfTotalMate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTotalReverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_evaluated = {\"order_code\":[] , \"position\":[], \"product_code\":[] ,  \"comment\" : [] ,\"total_quota\": [] , \n",
    "                  \"stockout_quantity\": [] , \"temporary_quantity\" : [] , \"lack_of_material\" : [] ,  \"quota\" : [] , \n",
    "                  \"lack_of_quantity\": [], \"is_outsourcing\" : []}\n",
    "listColMateTtReverse = [9,14,19,24,29]\n",
    "listColMate = [5,10,15,20,25] \n",
    "\n",
    "def updateDictEvaluated(dict_evaluated, aMate , comment, total_quota, stockout_quantity, \n",
    "                        temporary_quantity, lack_of_material, quota , lack_of_quantity , is_outsourcing):\n",
    "    dict_evaluated[\"order_code\"].append(aMate['order_code'])\n",
    "    dict_evaluated[\"position\"].append(aMate['position'])\n",
    "    dict_evaluated[\"product_code\"].append(aMate['product_code'])\n",
    "    dict_evaluated[\"comment\"].append(comment)\n",
    "    dict_evaluated[\"total_quota\"].append(total_quota)\n",
    "    dict_evaluated[\"stockout_quantity\"].append(stockout_quantity)\n",
    "    dict_evaluated[\"temporary_quantity\"].append(temporary_quantity)\n",
    "    dict_evaluated[\"lack_of_material\"].append(lack_of_material)\n",
    "    dict_evaluated[\"quota\"].append(quota)\n",
    "    dict_evaluated[\"lack_of_quantity\"].append(lack_of_quantity)\n",
    "    dict_evaluated[\"is_outsourcing\"].append(is_outsourcing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calLevel1(ahat, total_missing_quota, dfParent):\n",
    "    sub = ahat['temporary_quantity'] - total_missing_quota\n",
    "    indexCode = dfParent[dfParent['product_code'] == ahat['product_code']].index[0] \n",
    "    dfParent.at[indexCode , 'temporary_quantity'] = sub\n",
    "    sub = np.round(sub, 2)\n",
    "    return sub, dfParent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the quantity of material after using it\n",
    "def replaceNewValue(aMate, dfParent , sub):\n",
    "    update_sub = 0\n",
    "    for i in listColMate: \n",
    "        if(aMate[i] != 0):\n",
    "            indexCode = dfParent[dfParent['product_code'] == aMate[i]].index[0]\n",
    "            update_sub = aMate[i+4] + (sub / aMate[i+2])\n",
    "            dfParent.at[indexCode , 'temporary_quantity'] = round(update_sub,2)\n",
    "        else:\n",
    "            break\n",
    "    return dfParent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTotalReverse.loc[dfTotalReverse[\"product_code\"] == \"5-DAFELT-BLK-07-TA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calLevel2(ahat , product_id, dfTotalMate , sub1 , sub , dict_evaluated, dfParent, dfTotalReverse , quota):\n",
    "    dict_notenough = {\"product_id\": [], \"index_min\": [] , \"quota\": [] ,\"quantity_product\": [] , \"temp_quantity\": []}\n",
    "    count = negative = positive = 0\n",
    "    aMate = dfTotalMate.loc[np.where(dfTotalMate['parent_product'] == product_id)[0][0]] \n",
    "    for i in listColMate: \n",
    "        if (aMate[5] == 0):\n",
    "            return updateDictEvaluated(dict_evaluated, ahat, \"not enough\", ahat['total_quota'] ,ahat['stockout_quantity'] ,sub1, aMate[i-4], quota , sub , 0)\n",
    "            \n",
    "        elif(aMate[i] != 0):\n",
    "            slSC = aMate[i+4] * aMate[i+2]\n",
    "            if((slSC + sub1) < 0):\n",
    "                dict_notenough['product_id'].append(aMate[i+1]) \n",
    "                dict_notenough['index_min'].append(i) \n",
    "                dict_notenough['quota'].append(quota * aMate[i+2]) \n",
    "                dict_notenough['quantity_product'].append(slSC) \n",
    "                dict_notenough['temp_quantity'].append(np.round((slSC + sub1)/aMate[i+2] , 2)) \n",
    "                negative = negative + 1\n",
    "            else:\n",
    "                positive = positive + 1\n",
    "            count = count + 1\n",
    "        else:\n",
    "            break\n",
    "                \n",
    "    df_notenough = pd.DataFrame(dict_notenough)\n",
    "        \n",
    "    dfParent = replaceNewValue(aMate, dfParent , sub)\n",
    "    dfTotalMate,dfTotalReverse = mergeMaterialOrder(dfChild , dfParent, dfOrder)\n",
    "    \n",
    "    if(count == positive):\n",
    "        return updateDictEvaluated(dict_evaluated, ahat, \"enough\", ahat['total_quota'] , ahat['stockout_quantity'], sub1, np.NaN, quota , np.NaN, np.NaN)    \n",
    "    else:    \n",
    "        for i in range(0, negative):\n",
    "            return calLevel2(ahat, df_notenough.loc[i]['product_id'], dfTotalMate , sub1, df_notenough.loc[i]['temp_quantity'], dict_evaluated, dfParent, dfTotalReverse, df_notenough.loc[i]['quota'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary(dfTotalReverse , dfParent, dfTotalMate, index):\n",
    "    ahat = dfTotalReverse.loc[index]\n",
    "    total_missing_quota = ahat['total_quota'] - ahat['stockout_quantity'] \n",
    "    if(total_missing_quota <= 0.0):\n",
    "        updateDictEvaluated(dict_evaluated, ahat, \"exported\", ahat['total_quota'] , ahat['stockout_quantity'], np.NAN, np.NAN , np.NAN , np.NAN, np.NAN)\n",
    "    else: \n",
    "        if(ahat['is_outsourcing'] == 0):\n",
    "            sub, dfParent = calLevel1(ahat, total_missing_quota, dfParent)\n",
    "            dfTotalMate,dfTotalReverse = mergeMaterialOrder(dfChild , dfParent, dfOrder)\n",
    "            if(sub > 0):\n",
    "                updateDictEvaluated(dict_evaluated, ahat, \"enough\", ahat['total_quota'] , ahat['stockout_quantity'], sub, np.NAN, np.NAN, np.NAN , 0)\n",
    "            else:\n",
    "                updateDictEvaluated(dict_evaluated, ahat, \"not enough\", ahat['total_quota'] , ahat['stockout_quantity'], sub , ahat[\"product_code\"],np.NAN, sub , 0)\n",
    "        else:\n",
    "            sub1, dfParent = calLevel1(ahat, total_missing_quota, dfParent)\n",
    "            sub = np.NAN\n",
    "            dfTotalMate,dfTotalReverse = mergeMaterialOrder(dfChild , dfParent, dfOrder)\n",
    "            if(sub1 > 0):\n",
    "                updateDictEvaluated(dict_evaluated, ahat, \"enough\", ahat['total_quota'] , ahat['stockout_quantity'], sub1 , np.NAN,  np.NAN, np.NAN , 1)\n",
    "            else:\n",
    "                calLevel2(ahat , ahat['parent_product'], dfTotalMate , sub1 , sub , dict_evaluated, dfParent, dfTotalReverse , 1)\n",
    "    return dfTotalMate, dfTotalReverse\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTotalReverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(dfTotalReverse)):\n",
    "    dfTotalMate, dfTotalReverse = primary(dfTotalReverse ,dfParent, dfTotalMate, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEvaluted = pd.DataFrame.from_dict(dict_evaluated)\n",
    "# dfEvaluted = dfEvaluted[::-1].reset_index(drop = True)\n",
    "dfEvaluted.to_excel('data.xlsx')\n",
    "dfEvaluted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOrder = dfEvaluted['order_code'].unique()\n",
    "newDictEvalue = {\"order_code\": [] , \"comment\": []}\n",
    "for i in listOrder:\n",
    "    listEva = dfEvaluted.loc[dfEvaluted['order_code'] == i]['comment'].unique()\n",
    "    if (len(listEva) == 1):\n",
    "        newDictEvalue[\"comment\"].append(listEva[0])\n",
    "        newDictEvalue[\"order_code\"].append(i)\n",
    "    else:\n",
    "        if(listEva[0] != listEva[1]):\n",
    "            newDictEvalue[\"comment\"].append(\"not enough\")\n",
    "            newDictEvalue[\"order_code\"].append(i)\n",
    "        else:\n",
    "            newDictEvalue[\"comment\"].append(listEva)\n",
    "        \n",
    "dfEvalutedTt = pd.DataFrame.from_dict(newDictEvalue)\n",
    "# dfEvalutedTt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfEvalutedTt.loc[dfEvalutedTt[\"quantity\"] == \"enough\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfEvalutedTt.loc[dfEvalutedTt[\"quantity\"] == \"not enough\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
